{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pyathena\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import s3fs\n",
    "import sys\n",
    "#https://wiki.bugwood.org/Botrytis_cinerea\n",
    "#https://www.horticulture.com.au/globalassets/hort-innovation/resource-assets/ny15002-botrytis-fact-sheet.pdf\n",
    "# rh 93-100, temp 18-23, reduces below 15 and above 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e1ae2",
   "metadata": {},
   "source": [
    "#TODO\n",
    "\n",
    "1. Longest pos sum -hum\n",
    "\n",
    "2. Longest neg sum temp-dew diff\n",
    "\n",
    "3. Longest sum ,  temp in band, score 1 if within\n",
    "\n",
    "4. Regression class from outside forecast to GH weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyathena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ef1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../yield_prediction/fr-yield-prediction/notebooks/notebook_utils')\n",
    "sys.path.insert(0, '../yield_prediction/fr-yield-prediction/src')\n",
    "sys.path.insert(0, '../yield_prediction/fr-yield-prediction/src/utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport notebook_helpers\n",
    "%aimport data_imputers\n",
    "%aimport data_processors\n",
    "%aimport model_data_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a633b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8582738",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca151a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['inside_light_hr','inside_temp_hr','inside_rh_hr', 'dewpoint_hr']\n",
    "\n",
    "ns_drop = ['datetime','date', 'time', 'hitemp', 'lowtemp', 'dewpt', 'windspeed', 'winddir', \n",
    "        'windrun', 'hispeed',  'hidir', 'windchill', 'heatindex', 'thwindex', 'thswindex', 'bar', \\\n",
    "       'rain', 'rainrate', 'solarenergy', 'hi_solarrad',  'uv_index', 'uv_dose', 'hi_uv', \\\n",
    "        'heatdd', 'cooldd', 'in_temp', 'inhum', 'in_heat', 'et', 'windsamp',  \\\n",
    "        'windtx', 'iss_recept', 'arcint', 'in_emc', 'in_air_density', 'source', 'ingestion_date', 'year']\n",
    "\n",
    "ns_event_names = {'solarrad': 'inside_light_hr', \n",
    "                'tempout': 'inside_temp_hr',\n",
    "                'outhum':  'inside_rh_hr',\n",
    "                'in_dew': 'dewpoint_hr'\n",
    "                 }\n",
    "\n",
    "light_hours = {\n",
    "    'summer': [6,19],\n",
    "    'winter': [8,17]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_temp_dict = {\n",
    "     'botrytis': {\n",
    "                  'hours' : 24,                \n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 93,\n",
    "                          \"step_size\": 2.5},         \n",
    "                    \n",
    "                  'inside_temp_hr': {\"bound\" : 'between',\n",
    "                      \"low_threshold_value\" : 15,\n",
    "                     \"high_threshold_value\" : 25} \n",
    "         \n",
    "                },\n",
    "    \n",
    "    'powdery_mildew': {\n",
    "                 'hours': 8,\n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 90,\n",
    "                            \"step_size\": 5}, \n",
    "                  'inside_temp_hr': {\"bound\" : 'low',\n",
    "                          \"threshold_value\" : 25,\n",
    "                          \"step_size\": 2.5}\n",
    "                  },\n",
    "\n",
    "    'late_blight': {\n",
    "                 'hours': 8,\n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 90,\n",
    "                            \"step_size\": 5}, \n",
    "                  'inside_temp_hr': {\"bound\" : 'low',\n",
    "                          \"threshold_value\" : 25,\n",
    "                          \"step_size\": 2.5}\n",
    "                }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "disease_dew_dict = {\n",
    "     'botrytis': {\n",
    "                  'hours' : 24,                \n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 93,\n",
    "                          \"step_size\": 2.5},\n",
    "         \n",
    "                     'temp_dew_diff': {\"bound\" : 'low',\n",
    "                          \"threshold_value\" : 0,\n",
    "                          \"step_size\": 1.5},\n",
    "\n",
    "#                   'inside_temp_hr': {\"bound\" : 'low',\n",
    "#                           \"threshold_value\" : 25,\n",
    "#                           \"step_size\": 2.5}\n",
    "         \n",
    "                  'inside_temp_hr': {\"bound\" : 'between',\n",
    "                      \"low_threshold_value\" : 15,\n",
    "                     \"high_threshold_value\" : 25} \n",
    "         \n",
    "                },\n",
    "    \n",
    "    'powdery_mildew': {\n",
    "                 'hours': 8,\n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 90,\n",
    "                            \"step_size\": 5}, \n",
    "                  'inside_temp_hr': {\"bound\" : 'low',\n",
    "                          \"threshold_value\" : 25,\n",
    "                          \"step_size\": 2.5}\n",
    "                  },\n",
    "\n",
    "    'late_blight': {\n",
    "                 'hours': 8,\n",
    "                  'inside_rh_hr': {\"bound\" : 'high',\n",
    "                          \"threshold_value\" : 90,\n",
    "                            \"step_size\": 5}, \n",
    "                  'inside_temp_hr': {\"bound\" : 'low',\n",
    "                          \"threshold_value\" : 25,\n",
    "                          \"step_size\": 2.5}\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f513186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODADD\n",
    "def impute_night_light(df, light_hours, light_base_value=5):\n",
    "    '''\n",
    "    df = hourly data\n",
    "    Light at night is around zero but this value is noisy and not ideal for data stsrndadisation.\n",
    "    We set it to a base value to stabilise variance around zero.\n",
    "    We flag hours during the day with near zero light for verification\n",
    "    '''\n",
    "    # set noisy out hours to baseline\n",
    "    summer = light_hours['summer']\n",
    "    winter = light_hours['winter']\n",
    "    \n",
    "    # initialise flag for noisy light data hours\n",
    "    df['check_light_data'] = [0]*len(df)\n",
    "    \n",
    "    for idx, row in df.iterrows() : \n",
    "        # absolute night hours\n",
    "        if (row['hour'] < summer[0]) or (row['hour'] > summer[1]):\n",
    "            df.at[idx, 'inside_light_hr'] = light_base_value \n",
    "        # border line night hours     \n",
    "        if (row['hour'] <= winter[0]) or (row['hour'] >= winter[1]): \n",
    "            if row['inside_light_hr'] < light_base_value:\n",
    "                df.at[idx, 'inside_light_hr'] = light_base_value \n",
    "        # possibly noise data during day\n",
    "        if winter[0] < row['hour'] < winter[1]:    \n",
    "            if row['inside_light_hr'] < light_base_value:        \n",
    "                df.at[idx, 'check_light_data'] = 1\n",
    "    \n",
    "    # remove noisy data during day\n",
    "    # logg this \n",
    "    suspicious_pc = round(100* df['check_light_data'].mean(),3)\n",
    "    first_date = df.loc[df['check_light_data'] == 1,'event_date_time'].min()\n",
    "    print(f\"Check {suspicious_pc}% supiscious light reading daytime from {first_date}\")\n",
    "    \n",
    "    return df[df['check_light_data'] == 0], df[df['check_light_data'] == 1]\n",
    "\n",
    "\n",
    "\n",
    "#PRODADD\n",
    "def year_week_select_complete_days(df, hours_threshold=20):\n",
    "    '''\n",
    "    df = dataframe after datetime slicing\n",
    "    Slicing days by datetime return midnight of last day. \n",
    "    this means only 0000Hr data for that day. these days needs to be dropped \n",
    "    from the analysis.\n",
    "    Apply this method after date time slicing. This is important to in calculating seasona indexes (SI).\n",
    "    Ideally 24 hours are expected in a day. Thresshold set to 20 to accomodate days with few missing hours.\n",
    "    Over a number of days averaging with few missing hours randomly should not impact SI calculation\n",
    "    significantly\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # for each week drop the lone MN hour days from grouping\n",
    "    df['filter_index'] = df['year_week'] + df['day'].astype('str')\n",
    "    days_to_keep = df.groupby('filter_index')['hour'] \\\n",
    "                         .count()[df.groupby('filter_index')['hour'].count() >= hours_threshold] \\\n",
    "                         .index\n",
    "\n",
    "\n",
    "    df_out = df[df['filter_index'].isin(days_to_keep)]\n",
    "\n",
    "    return df_out.drop(columns='filter_index')\n",
    "\n",
    "\n",
    "def drop_zero_read_hours(df, measures):\n",
    "    # removes hours with zero readings, possible device error\n",
    "    return  df[~(df[measures] == 0).any(axis=1)]\n",
    "\n",
    "\n",
    "def longest_signed_run(x_array):\n",
    "    # sum of longest run of positives or negatives in array\n",
    "        \n",
    "    res_pos = 0 \n",
    "    cnt_pos = 0\n",
    "    for num in x_array:\n",
    "        if num > 0:\n",
    "            cnt_pos += 1\n",
    "            #print(cnt_pos)\n",
    "        else:\n",
    "            res_pos = max(res_pos, cnt_pos)\n",
    "            cnt_pos = 0\n",
    "    res_pos = max(res_pos, cnt_pos)\n",
    "    #print(res_pos)\n",
    "    \n",
    "    res_neg = 0 \n",
    "    cnt_neg = 0\n",
    "    for num in x_array:\n",
    "        if num < 0:\n",
    "            cnt_neg += 1\n",
    "            #print(cnt_neg)\n",
    "        else:\n",
    "            res_neg = min(res_neg, cnt_neg)\n",
    "            cnt_neg = 0\n",
    "    res_neg = min(res_neg, cnt_neg)\n",
    "    #print(res_neg)\n",
    "    \n",
    "    return res_pos, res_neg\n",
    "\n",
    "\n",
    "\n",
    "def longest_signed_sum(x_array):\n",
    "    # returns the sum of longest run of positives or negatives in array\n",
    "        \n",
    "    res_pos = 0 \n",
    "    sum_pos = 0\n",
    "    for num in x_array:\n",
    "        if num > 0:\n",
    "            sum_pos += num\n",
    "            #print(sum_pos)\n",
    "        else:\n",
    "            res_pos = max(res_pos, sum_pos)\n",
    "            sum_pos = 0\n",
    "    res_pos = max(res_pos, sum_pos)\n",
    "    #print(res_pos)\n",
    "    \n",
    "    res_neg = 0 \n",
    "    sum_neg = 0\n",
    "    for num in x_array:\n",
    "        if num < 0:\n",
    "            sum_neg += num\n",
    "            #print(sum_neg)\n",
    "        else:\n",
    "            res_neg = min(res_neg, sum_neg)\n",
    "            sum_neg = 0\n",
    "    res_neg = min(res_neg, sum_neg)\n",
    "    #print(res_neg)\n",
    "    \n",
    "    return res_pos, res_neg\n",
    "\n",
    "\n",
    "\n",
    "def variance_score(xi, bound, threshold_value, step_size):\n",
    "    score = 0\n",
    "    var_ = xi - threshold_value\n",
    "    if bound == 'low':\n",
    "        if var_ < 0:\n",
    "            score = abs(round(var_ / step_size,0))\n",
    "        else:\n",
    "            score = 0\n",
    "    if bound == 'high':\n",
    "        if var_ > 0:\n",
    "            score = round(var_ / step_size,0)\n",
    "        else:\n",
    "            print('fuck you')\n",
    "            score = 0\n",
    "            print(score)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def variance_event(xi, bound, threshold_value, step_size):\n",
    "    count = 0\n",
    "    var_ = xi - threshold_value\n",
    "    if bound == 'low':\n",
    "        if var_ < 0:\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "    if bound == 'high':\n",
    "        if var_ > 0:\n",
    "            count = 1\n",
    "        else:\n",
    "            #print('fuck you')\n",
    "            count = 0\n",
    " \n",
    "    return count\n",
    "\n",
    "\n",
    "def sel_data(data, feat, len_=10):    \n",
    "    return data[feat][-len_:]   \n",
    "\n",
    "\n",
    "def overall_score(scores, events, conditions=2):\n",
    "    ov_score = 0\n",
    "    ov_events = 0\n",
    "    \n",
    "    if conditions == 2:    \n",
    "        for x, y in zip(scores[0],scores[1]):\n",
    "            if x > 0 and y > 0:\n",
    "                ov_events += 1\n",
    "                tot = x+y\n",
    "                ov_score += tot \n",
    "                \n",
    "    \n",
    "    if conditions == 3:    \n",
    "        for x, y, z in zip(scores[0],scores[1], scores[2]):\n",
    "            if x > 0 and y > 0 and z > 0:\n",
    "                ov_events += 1\n",
    "                tot = x + y + z\n",
    "                ov_score += tot  \n",
    "                \n",
    "    return ov_score, ov_events\n",
    "\n",
    "\n",
    "def model_risk_scores(data, disease, conditions=2, disease_dict=disease_dict): \n",
    "    events = []\n",
    "    scores = []\n",
    "    cont_run_stats = {}\n",
    "    cont_sum_stats = {}    \n",
    "    for feat in list(disease_dict[disease].keys())[1:]:\n",
    "        dur = disease_dict[disease]['hours']\n",
    "        bound = disease_dict[disease][feat]['bound']\n",
    "        x = sel_data(data, feat=feat, len_=dur)\n",
    "        print(x)\n",
    "        score_x = []\n",
    "        event_x = []\n",
    "        \n",
    "        if bound != 'between':\n",
    "            threshold_value = disease_dict[disease][feat]['threshold_value'] \n",
    "            step_size = disease_dict[disease][feat]['step_size'] \n",
    "            x = sel_data(data, feat=feat, len_=dur)\n",
    "       \n",
    "            for xi in x:\n",
    "                score_x.append(variance_score(xi, bound, threshold_value, step_size))\n",
    "                event_x.append(variance_event(xi, bound, threshold_value, step_size))   \n",
    "            cont_run , _  = longest_signed_run(event_x)        \n",
    "            cont_sum , _  = longest_signed_sum(score_x)\n",
    "            print(\"event_x :\", event_x)     \n",
    "            print('score_x :', score_x)\n",
    "            \n",
    "        elif bound == 'between':           \n",
    "            # low and high bounds\n",
    "            low_ = disease_dict[disease][feat]['low_threshold_value']\n",
    "            high_ = disease_dict[disease][feat]['high_threshold_value'] \n",
    "           \n",
    "            for xi in x:    \n",
    "                score_x.append(select_constraint(xi, [low_, high_]))\n",
    "            print(\"constraint :\", score_x)\n",
    "\n",
    "            \n",
    "        cont_run_stats[feat] = cont_run\n",
    "        cont_sum_stats[feat] = cont_sum\n",
    "        events.append(event_x)\n",
    "        scores.append(score_x)\n",
    "        scores.append(cont_sum_stats)\n",
    "    print('scores')\n",
    "    print(scores)\n",
    "      \n",
    "    # all conditions met, i.e. temp low and hum high in same hour\n",
    "    ov_risk_score, ov_risk_hrs = overall_score(scores, events, conditions)\n",
    "    \n",
    "    return ov_risk_score, ov_risk_hrs\n",
    "\n",
    "    \n",
    "def hist_hourly_miss_percent(df, history_horizon=56): \n",
    "    \"\"\"\n",
    "    Data can missing in anumber of ways.\n",
    "    1. No data may received from the Folium for some hours or days\n",
    "    2. From this data, some entries can be missing.\n",
    "    The expected data hours are calculated for any given number of weeks.\n",
    "    The missing percent data is calculated as number of \n",
    "    \"\"\"\n",
    "    expected_rows = history_horizon*24 # hours in the weeks to analyse, e.g 8\n",
    "    print(\"Expected data hours :\", expected_rows)\n",
    "    miss_n = (df.isna().sum(axis=1) > 0).sum() # missing rows in received data\n",
    "    print(\"Missing data hours in the retrieved dataset :\", miss_n)\n",
    "    available_rows = len(df) - miss_n # rows available for analysis\n",
    "    print(\"Complete data hours :\", available_rows)\n",
    "    miss_prop = round(((expected_rows - available_rows)/ expected_rows),4)\n",
    "    miss_pc = 100* miss_prop\n",
    "    print(f\"{miss_pc} % data hours missing\")\n",
    "    \n",
    "    return miss_prop\n",
    "\n",
    "#PRODADD\n",
    "def select_complete_days(df, hours_threshold=20):\n",
    "    '''\n",
    "    df = dataframe after datetime slicing, wide for folium features\n",
    "    Slicing days by datetime return midnight of last day. \n",
    "    this means only 0000Hr data for that day. these dayas needs to be dropped \n",
    "    from the analysis.\n",
    "    Apply this method after date time slicing. This is important to in calculating seasona indexes (SI).\n",
    "    Ideally 24 hours are expected in a day. Thresshold set to 20 to accomodate days with few missing hours.\n",
    "    Over a number of days averaging with few missing hours randomly should not impact SI calculation\n",
    "    significantly\n",
    "    '''\n",
    "    days_to_keep = df.groupby('day')['hour'] \\\n",
    "                     .count()[df.groupby('day')['hour'].count() >= hours_threshold] \\\n",
    "                     .index.to_list()\n",
    "    \n",
    "    return df[df['day'].isin(days_to_keep)]\n",
    "\n",
    "def fix_hourly_data(df):\n",
    "    '''\n",
    "    df is dat is data with only features and not yield\n",
    "    'event_date_time' column for time stamp is expected\n",
    "    '''\n",
    "    df = df[~pd.isna(df['event_date_time'])]\n",
    "    df['event_date_time'] = pd.to_datetime(df['event_date_time'])\n",
    "    return df\n",
    "#OK\n",
    "\n",
    "def sort_hourly_data(df):\n",
    "    df['event_date_time'] = pd.to_datetime(df['event_date_time'])    \n",
    "    return df.set_index('event_date_time').sort_index()\n",
    "#OK\n",
    "\n",
    "#PRODADD\n",
    "#TODOM make sure start date, beginning of harvest week\n",
    "def create_history_data(df, start_date, horizon=56, hours_threshold=20):  \n",
    "    '''\n",
    "    df : df\n",
    "        df with datetime as index\n",
    "    start_date: str in form, '2022-12-26' \n",
    "    horizon: int\n",
    "            days to scan back for env patterns    \n",
    "    '''\n",
    "    q_start_date = pd.Timestamp(start_date) - DateOffset(days=horizon)\n",
    "    q_end_date = pd.Timestamp(start_date)\n",
    "    out_ = df.loc[q_start_date : q_end_date]\n",
    "    \n",
    "    # drop lonely midnight hour on the last day selected \n",
    "    out = select_complete_days(out_, hours_threshold)\n",
    "    \n",
    "    return out\n",
    "# OK\n",
    "\n",
    "\n",
    "def select_constraint(xi, bounds):\n",
    "    if bounds[0] <= xi <= bounds[1]:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def weekly_incidence_data(df, disease='Botrytis'):\n",
    "    return df.loc[df['disease']==disease,:]\n",
    "\n",
    "\n",
    "def gh_weekly_incidence_data(df, gh, disease='botrytis'):\n",
    "    return df.loc[(df['GH']==gh) &(df['disease']==disease),:]\n",
    "\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d06cc6",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_session = boto3.session.Session(profile_name='research-sso')\n",
    "s3_client = aws_session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NS Environment and Disease data\n",
    "env_q = \"\"\"select * from flattened_raw_db.naturesweet_external_environment\"\"\"\n",
    "\n",
    "pnd_q = \"\"\" select * from flattened_raw_db.naturesweet_pests_diseases\"\"\"\n",
    "\n",
    "mock_data = pd.read_csv(\"hourly_env_data.csv\")\n",
    "ns_env_pre = notebook_helpers.load_athena_data(query=env_q, env='research-sso')\n",
    "ns_disease = notebook_helpers.load_athena_data(query=pnd_q, env='research-sso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be0b5c",
   "metadata": {},
   "source": [
    "#### 1. Environment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_env_pre.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_env_pre['event_date_time'] = pd.to_datetime(ns_env_pre['datetime']).dt.round('H')\n",
    "ns_env_pre = ns_env_pre.rename(columns = ns_event_names)\n",
    "ns_env_pre = ns_env_pre.drop(columns=ns_drop)\n",
    "\n",
    "# create timstamp index columns\n",
    "ns_env_pre['day'] = ns_env_pre['event_date_time'].dt.day_of_year\n",
    "ns_env_pre['hour'] = ns_env_pre['event_date_time'].dt.hour\n",
    "\n",
    "\n",
    "# impute data\n",
    "ns_env, ns_check_data = impute_night_light(ns_env_pre, light_hours, light_base_value=5)\n",
    "ns_env = drop_zero_read_hours(ns_env, measures)\n",
    "\n",
    "# average by hour\n",
    "# cleanup 12MN lone hour\n",
    "ns_env_data = pd.DataFrame(ns_env.groupby(['year_week','event_date_time','day','hour']).mean()) \\\n",
    "                .reset_index()\n",
    "#ns_env_data = year_week_select_complete_days(ns_env_data, hours_threshold=20)\n",
    "\n",
    "ns_env_data['temp_dew_diff'] = ns_env_data['dewpoint_hr'] - ns_env_data['inside_temp_hr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7002e",
   "metadata": {},
   "source": [
    "#### 2.  Disease data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef65d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018 = pd.read_excel('pestdiseases.xlsx', sheet_name='PYE 2018')\n",
    "pd2019 = pd.read_excel('pestdiseases.xlsx', sheet_name='PYE 2019')\n",
    "pd2020 = pd.read_excel('pestdiseases.xlsx', sheet_name='PYE 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018['GH'] = pd2018['GH'].fillna(method=\"ffill\")\n",
    "pd2019['GH'] = pd2019['GH'].fillna(method=\"ffill\")\n",
    "pd2020['GH'] = pd2020['GH'].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018 = pd2018[pd2018['disease']!='year_week']\n",
    "pd2019 = pd2018[pd2019['disease']!='year_week']\n",
    "pd2020 = pd2018[pd2020['disease']!='year_week']\n",
    "\n",
    "pd2018 = pd2018.drop_duplicates()\n",
    "pd2019 = pd2019.drop_duplicates()\n",
    "pd2020 = pd2020.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20df767",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018_inc = pd.DataFrame(pd.wide_to_long(pd2018, stubnames='W',i=['GH','disease'], j='week')).reset_index() # sep='_', suffix=r'\\w+')\n",
    "pd2018_inc['year_week'] = ['2018-' + '0' + str(x) if x < 10 else '2018-' + str(x) for x in pd2018_inc['week']]\n",
    "pd2018_inc.rename(columns={\"W\": 'incidence'}, inplace=True)\n",
    "\n",
    "pd2019_inc = pd.DataFrame(pd.wide_to_long(pd2019, stubnames='W',i=['GH','disease'], j='week')).reset_index() # sep='_', suffix=r'\\w+')\n",
    "pd2019_inc['year_week'] = ['2019-' + '0' + str(x) if x < 10 else '2019-' + str(x) for x in pd2019_inc['week']]\n",
    "pd2019_inc.rename(columns={\"W\": 'incidence'}, inplace=True)\n",
    "\n",
    "pd2020_inc = pd.DataFrame(pd.wide_to_long(pd2020, stubnames='W',i=['GH','disease'], j='week')).reset_index() # sep='_', suffix=r'\\w+')\n",
    "pd2020_inc['year_week'] = ['2020-' + '0' + str(x) if x < 10 else '2020-' + str(x) for x in pd2020_inc['week']]\n",
    "pd2020_inc.rename(columns={\"W\": 'incidence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1640f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2018_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5647a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disease = pd.concat([pd2018_inc, pd2019_inc, pd2020_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47aed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disease.disease.unique() # 'cenicilla', 'fulvia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da82bae",
   "metadata": {},
   "source": [
    "#### 3.  combine disease and env data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f97e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_disease = ns_env_data.merge(all_disease, on='year_week', suffixes=[\"\",\"_\"])\n",
    "env_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data pull\n",
    "test_gh = gh_weekly_incidence_data(env_disease, gh='J09', disease='Botrytis')\n",
    "test_gh[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06458393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gh.incidence.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbaddd2",
   "metadata": {},
   "source": [
    "### Botrytis Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "botrytis = weekly_incidence_data(env_disease, disease='Botrytis')\n",
    "botrytis[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "botrytis.dewpoint_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_all.incidence.min(), test_all.incidence.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "botrytis.incidence.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ce8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "botrytis['infected'] = [1 if x>0 else 0 for x in botrytis['incidence'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate weeks with Positive and Negative Botrytis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf69d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_pos = botrytis[botrytis['infected']==1]\n",
    "bot_neg = botrytis[botrytis['infected']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_pos['date_str'] = bot_pos['event_date_time'].dt.date.astype(str)\n",
    "bot_pos['gh_date_str'] = bot_pos['GH'] +  \"_\"  +  bot_pos['year_week']  +  \"_\"  +  bot_pos['date_str']\n",
    "\n",
    "bot_neg['date_str'] = bot_neg['event_date_time'].dt.date.astype(str)\n",
    "bot_neg['gh_date_str'] = bot_neg['GH']  +  \"_\"  +  bot_neg['year_week']  +  \"_\"  +  bot_neg['date_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_pos.groupby(['GH', 'year_week'])['gh_date_str'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c658965",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dates = bot_pos['gh_date_str'].unique()\n",
    "\n",
    "pos_week = []\n",
    "pos_event_date = []\n",
    "pos_scores = []\n",
    "pos_hours = []\n",
    "for date in pos_dates:\n",
    "    dat_ = bot_pos[bot_pos['gh_date_str']==date]\n",
    "    if len(dat_)==24:\n",
    "        pos_week.append(dat_['year_week'].values[0])\n",
    "        pos_event_date.append(date)\n",
    "        risk_score, ev_hours = model_risk_scores(dat_, 'botrytis', disease_dict=disease_dict)\n",
    "        pos_scores.append(risk_score) \n",
    "        pos_hours.append(ev_hours)\n",
    "        print(len(pos_dates), len(pos_scores), len(pos_hours))\n",
    "        \n",
    "pos_res = pd.DataFrame(\n",
    "            {'pos_week': pos_week,\n",
    "             'pos_dates': pos_event_date, \n",
    "             'pos_scores': pos_scores,\n",
    "             'pos_hours': pos_hours\n",
    "             })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e442bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_res.to_csv(\"pos_results.csv\")\n",
    "pos_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62932461",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dates = bot_neg['gh_date_str'].unique()\n",
    "#neg_dates = ['B01_2019-38_2019-09-19']\n",
    "\n",
    "neg_week = []\n",
    "neg_event_date = []\n",
    "neg_scores = []\n",
    "neg_hours = []\n",
    "for date in neg_dates:\n",
    "    dat_ = bot_neg[bot_neg['gh_date_str']==date]\n",
    "    if len(dat_)==24:\n",
    "        neg_week.append(dat_['year_week'].values[0])\n",
    "        neg_event_date.append(date)\n",
    "        risk_score, ev_hours = model_risk_scores(dat_, 'botrytis', disease_dict=disease_dict)\n",
    "        neg_scores.append(risk_score) \n",
    "        neg_hours.append(ev_hours)\n",
    "        \n",
    "        \n",
    "neg_res = pd.DataFrame(\n",
    "            {'neg_week': neg_week,\n",
    "             'neg_dates': neg_event_date, \n",
    "             'neg_scores': neg_scores,\n",
    "             'neg_hours': neg_hours\n",
    "             })  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_res.to_csv(\"neg_results.csv\")\n",
    "neg_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e6a7c",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc59cd",
   "metadata": {},
   "source": [
    "#### 1. Any days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e84508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = [1]*len(pos_scores)\n",
    "pos_roc = pd.DataFrame({'score': pos_scores, 'infected': pos_index })\n",
    "neg_index = [0]*len(neg_scores)\n",
    "neg_roc = pd.DataFrame({'score': neg_scores, 'infected': neg_index })\n",
    "bot_poc = pd.concat([pos_roc, neg_roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(bot_poc['infected'], bot_poc['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(bot_poc['infected'], bot_poc['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2beeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_poc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aabe50c",
   "metadata": {},
   "source": [
    "#### 2. Max infection day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f57d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_max = neg_res.groupby('neg_week')['neg_scores'].max()\n",
    "pos_max = pos_res.groupby('pos_week')['pos_scores'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c930e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filteres\n",
    "pos_index = [1]*len(pos_max)\n",
    "pos_roc_max = pd.DataFrame({'score': pos_max, 'infected': pos_index })\n",
    "neg_index = [0]*len(neg_max)\n",
    "neg_roc_max = pd.DataFrame({'score': neg_max, 'infected': neg_index })\n",
    "bot_poc_max = pd.concat([pos_roc_max, neg_roc_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(bot_poc_max['infected'], bot_poc_max['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e73528",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(bot_poc_max['infected'], bot_poc_max['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_max.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_max.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c833e96",
   "metadata": {},
   "source": [
    "## ------------- PLAY ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27672311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE END\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dates = bot_pos['gh_date_str'].unique()\n",
    "\n",
    "pos_week = []\n",
    "pos_event_date = []\n",
    "pos_scores = []\n",
    "pos_hours = []\n",
    "for date in pos_dates[-10:]:\n",
    "    dat_ = bot_pos[bot_pos['gh_date_str']==date]\n",
    "    if len(dat_)==24:\n",
    "        pos_week.append(dat_['year_week'].values[0])\n",
    "        pos_event_date.append(date)\n",
    "        risk_score, ev_hours, cont_score = model_risk_scores(dat_, 'botrytis', disease_dict=disease_dict)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff964b83",
   "metadata": {},
   "outputs": [],
   "source": [
    " risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_risk_scores(data, disease, conditions=2, disease_dict=disease_temp_dict): \n",
    "    events = []\n",
    "    scores = []\n",
    "    cont_scores = []\n",
    "    cont_run_stats = {}\n",
    "    cont_sum_stats = {}    \n",
    "    for feat in list(disease_dict[disease].keys())[1:]:\n",
    "        dur = disease_dict[disease]['hours']\n",
    "        bound = disease_dict[disease][feat]['bound']\n",
    "        x = sel_data(data, feat=feat, len_=dur)\n",
    "        print(x)\n",
    "        score_x = []\n",
    "        event_x = []\n",
    "        \n",
    "        if bound != 'between':\n",
    "            threshold_value = disease_dict[disease][feat]['threshold_value'] \n",
    "            step_size = disease_dict[disease][feat]['step_size'] \n",
    "            x = sel_data(data, feat=feat, len_=dur)\n",
    "       \n",
    "            for xi in x:\n",
    "                score_x.append(variance_score(xi, bound, threshold_value, step_size))\n",
    "                event_x.append(variance_event(xi, bound, threshold_value, step_size))   \n",
    "          \n",
    "            print(\"event_x :\", event_x)     \n",
    "            print('score_x :', score_x)\n",
    "            \n",
    "        elif bound == 'between':           \n",
    "            # low and high bounds\n",
    "            low_ = disease_dict[disease][feat]['low_threshold_value']\n",
    "            high_ = disease_dict[disease][feat]['high_threshold_value'] \n",
    "           \n",
    "            for xi in x:    \n",
    "                score_x.append(select_constraint(xi, [low_, high_]))\n",
    "            print(\"constraint :\", score_x)\n",
    "       \n",
    "        events.append(event_x)\n",
    "        scores.append(score_x)     \n",
    "        \n",
    "    print('scores')\n",
    "    print(scores)\n",
    "      \n",
    "    # all conditions met, i.e. temp low and hum high in same hour\n",
    "    ov_risk_score, ov_risk_hrs = overall_score_continous(scores, events, conditions)\n",
    "    \n",
    "    return ov_risk_score, ov_risk_hrs\n",
    "\n",
    "\n",
    "def overall_score_sparse(scores, events, conditions=2):\n",
    "    ov_score = 0\n",
    "    ov_events = 0\n",
    "    \n",
    "    if conditions == 2:    \n",
    "        for x, y in zip(scores[0],scores[1]):\n",
    "            if x > 0 and y > 0:\n",
    "                ov_events += 1\n",
    "                tot = x+y\n",
    "                ov_score += tot \n",
    "                \n",
    "    \n",
    "    if conditions == 3:    \n",
    "        for x, y, z in zip(scores[0],scores[1], scores[2]):\n",
    "            if x > 0 and y > 0 and z > 0:\n",
    "                ov_events += 1\n",
    "                tot = x + y + z\n",
    "                ov_score += tot  \n",
    "                \n",
    "    return ov_score, ov_events\n",
    "\n",
    "\n",
    "def overall_score_continous(scores, events, conditions=2):\n",
    "    ov_score = 0\n",
    "    ov_events = 0\n",
    "    \n",
    "    if conditions == 2: \n",
    "        tot = []\n",
    "        for x, y in zip(scores[0],scores[1]):\n",
    "            if x > 0 and y > 0:                \n",
    "                ov_events += 1               \n",
    "                tot.append(x+y)\n",
    "            else:\n",
    "                tot.append(0)\n",
    "        print(tot)        \n",
    "        ov_score, _ =  longest_signed_sum(tot)\n",
    "        print(ov_score)\n",
    "\n",
    "    \n",
    "    if conditions == 3:    \n",
    "        for x, y, z in zip(scores[0],scores[1], scores[2]):\n",
    "            tot = []\n",
    "            if x > 0 and y > 0 and z > 0:\n",
    "                ov_events += 1\n",
    "                tot.append(x + y + z)\n",
    "        ov_score, _ =  longest_signed_sum(tot)\n",
    "        print(ov_score)\n",
    "\n",
    "    return ov_score, ov_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0614f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = [x for x in range(0,24)]\n",
    "temp = [x + np.random.normal(17,3)  for x in range(0,24)]\n",
    "rh = [x + np.random.normal(90,5)  for x in range(0,24)]\n",
    "dew = [x + np.random.normal(-3,1)  for x in range(0,24)]\n",
    "\n",
    "mock_data = pd.DataFrame({'hour': hour,\n",
    "                        'inside_temp_hr': temp,\n",
    "                         'inside_rh_hr': rh,\n",
    "                         'temp_dew_diff': dew}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea99ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_score, ev_hours = model_risk_scores(mock_data, 'botrytis', disease_dict=disease_temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33234a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c738766",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 5.0, 3.0, 5.0, 5.0, 6.0, 5.0, 6.0, 9.0, 7.0, 9.0, 7.0, 7.0, 8.0, 8.0, 10.0, 12.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86489a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([2.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =[0.0, 0, 0, 2.0, 0, 0.0, 2.0, 0, 4.0, 6.0, 0, 1.0, 6.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 8.0, 9.0, 9.0, 8.0, 11.0]\n",
    "x=[0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for x_, y_ in zip(x,y):\n",
    "    print(x_, y_)\n",
    "    #print(x_+y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8007f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
